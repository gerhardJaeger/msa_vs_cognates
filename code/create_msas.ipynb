{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "source": [
    "# Creating character matrices from multiple sequence alignments produced with tCoffee based on Needleman-Wunsch alignment with PMI distances from ASJP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/localscratch/nwsja01/projects/msa_vs_cognates/code`\n"
     ]
    }
   ],
   "source": [
    "cd(@__DIR__)\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y r-phangorn` in root environment\n",
      "└ @ Conda /localscratch/nwsja01/.julia/packages/Conda/sDjAP/src/Conda.jl:181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - r\n",
      " - defaults\n",
      " - conda-forge\n",
      " - bioconda\n",
      " - fvcore\n",
      " - iopath\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /localscratch/nwsja01/miniconda3/envs/stringAutoencoder\n",
      "\n",
      "  added / updated specs:\n",
      "    - r-phangorn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    arpack-3.8.0               |nompi_h0baa96a_101         214 KB  conda-forge\n",
      "    brotli-python-1.0.9        |   py38h6a678d5_8         356 KB\n",
      "    conda-23.3.1               |   py38h06a4308_0         960 KB\n",
      "    cryptography-41.0.7        |   py38hdda0065_0         2.0 MB\n",
      "    curl-8.7.1                 |       hdbd6064_0          86 KB\n",
      "    cyrus-sasl-2.1.28          |       h52b45da_1         237 KB\n",
      "    expat-2.6.2                |       h6a678d5_0         177 KB\n",
      "    git-2.40.1                 | pl5340h36fbf9e_1         9.9 MB\n",
      "    icu-73.1                   |       h6a678d5_0        25.9 MB\n",
      "    julia-1.10.1               |       h764f291_0       101.1 MB  conda-forge\n",
      "    libclang-14.0.6            |default_hc6dbbc7_1         137 KB\n",
      "    libclang13-14.0.6          |default_he11475f_1         9.8 MB\n",
      "    libcups-2.4.2              |       h2d74bed_1         4.5 MB\n",
      "    libcurl-8.7.1              |       h251f7ec_0         424 KB\n",
      "    libgfortran-ng-13.2.0      |       h69a702a_0          23 KB  conda-forge\n",
      "    libgfortran5-13.2.0        |       ha4646dd_0         1.4 MB  conda-forge\n",
      "    libgit2-1.7.2              |       h76de150_0         842 KB  conda-forge\n",
      "    libllvm14-14.0.6           |       hdb19cb5_3        33.4 MB\n",
      "    libmambapy-1.4.2           |   py38h7fa060d_0         261 KB  conda-forge\n",
      "    libopenlibm4-0.8.1         |       hd590300_1         102 KB  conda-forge\n",
      "    libssh2-1.11.0             |       h251f7ec_0         282 KB\n",
      "    libutf8proc-2.8.0          |       h166bdaf_0          99 KB  conda-forge\n",
      "    libxkbcommon-1.0.1         |       h5eee18b_1         590 KB\n",
      "    libxslt-1.1.37             |       h5eee18b_1         266 KB\n",
      "    mamba-1.4.2                |   py38haad2881_0          49 KB  conda-forge\n",
      "    mysql-5.7.24               |       h721c034_2        60.0 MB\n",
      "    pcre2-10.42                |       hebb0a14_1         1.3 MB\n",
      "    pycosat-0.6.6              |   py38h5eee18b_1          93 KB\n",
      "    python-3.8.16              |he550d4f_1_cpython        21.8 MB  conda-forge\n",
      "    python_abi-3.8             |           4_cp38           6 KB  conda-forge\n",
      "    qt-main-5.15.2             |      h53bd1ea_10        53.7 MB\n",
      "    r-ape-5.7_1                |    r43h884c59f_0         3.0 MB  r\n",
      "    r-cli-3.6.1                |    r43h884c59f_0         1.2 MB  r\n",
      "    r-cpp11-0.4.6              |    r43h6115d3f_0         221 KB\n",
      "    r-digest-0.6.33            |    r43h884c59f_0         215 KB  r\n",
      "    r-fastmatch-1.1_4          |    r43h76d94ec_0          48 KB  r\n",
      "    r-generics-0.1.3           |    r43h142f84f_0          81 KB\n",
      "    r-glue-1.6.2               |    r43h76d94ec_0         154 KB  r\n",
      "    r-lattice-0.21_9           |    r43h76d94ec_0         1.3 MB  r\n",
      "    r-lifecycle-1.0.3          |    r43h142f84f_0         116 KB\n",
      "    r-magrittr-2.0.3           |    r43h76d94ec_0         214 KB  r\n",
      "    r-matrix-1.6_1.1           |    r43h76d94ec_0         4.3 MB  r\n",
      "    r-nlme-3.1_163             |    r43h640688f_0         2.3 MB  r\n",
      "    r-phangorn-2.11.1          |    r43h884c59f_0         2.5 MB  r\n",
      "    r-pkgconfig-2.0.3          |    r43h6115d3f_0          24 KB\n",
      "    r-quadprog-1.5_8           |    r43h640688f_0          47 KB  r\n",
      "    r-rcpp-1.0.11              |    r43h884c59f_0         2.1 MB  r\n",
      "    r-rlang-1.1.1              |    r43h884c59f_0         1.5 MB  r\n",
      "    ruamel.yaml-0.17.21        |   py38h5eee18b_0         178 KB\n",
      "    ruamel.yaml.clib-0.2.6     |   py38h5eee18b_1         143 KB\n",
      "    xz-5.4.6                   |       h5eee18b_1         643 KB\n",
      "    zstandard-0.19.0           |   py38h5eee18b_0         474 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       350.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cyrus-sasl         pkgs/main/linux-64::cyrus-sasl-2.1.28-h52b45da_1 \n",
      "  libclang13         pkgs/main/linux-64::libclang13-14.0.6-default_he11475f_1 \n",
      "  libcups            pkgs/main/linux-64::libcups-2.4.2-h2d74bed_1 \n",
      "  libllvm14          pkgs/main/linux-64::libllvm14-14.0.6-hdb19cb5_3 \n",
      "  libopenlibm4       conda-forge/linux-64::libopenlibm4-0.8.1-hd590300_1 \n",
      "  mysql              pkgs/main/linux-64::mysql-5.7.24-h721c034_2 \n",
      "  r-ape              r/linux-64::r-ape-5.7_1-r43h884c59f_0 \n",
      "  r-cli              r/linux-64::r-cli-3.6.1-r43h884c59f_0 \n",
      "  r-cpp11            pkgs/r/noarch::r-cpp11-0.4.6-r43h6115d3f_0 \n",
      "  r-digest           r/linux-64::r-digest-0.6.33-r43h884c59f_0 \n",
      "  r-fastmatch        r/linux-64::r-fastmatch-1.1_4-r43h76d94ec_0 \n",
      "  r-generics         pkgs/r/noarch::r-generics-0.1.3-r43h142f84f_0 \n",
      "  r-glue             r/linux-64::r-glue-1.6.2-r43h76d94ec_0 \n",
      "  r-igraph           r/linux-64::r-igraph-1.5.1-r43hb5eb8f6_0 \n",
      "  r-lattice          r/linux-64::r-lattice-0.21_9-r43h76d94ec_0 \n",
      "  r-lifecycle        pkgs/r/noarch::r-lifecycle-1.0.3-r43h142f84f_0 \n",
      "  r-magrittr         r/linux-64::r-magrittr-2.0.3-r43h76d94ec_0 \n",
      "  r-matrix           r/linux-64::r-matrix-1.6_1.1-r43h76d94ec_0 \n",
      "  r-nlme             r/linux-64::r-nlme-3.1_163-r43h640688f_0 \n",
      "  r-phangorn         r/linux-64::r-phangorn-2.11.1-r43h884c59f_0 \n",
      "  r-pkgconfig        pkgs/r/noarch::r-pkgconfig-2.0.3-r43h6115d3f_0 \n",
      "  r-quadprog         r/linux-64::r-quadprog-1.5_8-r43h640688f_0 \n",
      "  r-rcpp             r/linux-64::r-rcpp-1.0.11-r43h884c59f_0 \n",
      "  r-rlang            r/linux-64::r-rlang-1.1.1-r43h884c59f_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  arpack                                   3.7.0-hdefa2d7_2 --> 3.8.0-nompi_h0baa96a_101 \n",
      "  c-ares                                  1.18.1-h7f98852_0 --> 1.28.1-hd590300_0 \n",
      "  cryptography       conda-forge::cryptography-41.0.3-py31~ --> pkgs/main::cryptography-41.0.7-py38hdda0065_0 \n",
      "  curl                                    7.88.1-hdbd6064_2 --> 8.7.1-hdbd6064_0 \n",
      "  expat                 conda-forge::expat-2.4.8-h27087fc_0 --> pkgs/main::expat-2.6.2-h6a678d5_0 \n",
      "  fontconfig         pkgs/main::fontconfig-2.14.1-hef1e5e3~ --> conda-forge::fontconfig-2.14.2-h14ed4e7_0 \n",
      "  freetype           conda-forge::freetype-2.10.4-h0708190~ --> pkgs/main::freetype-2.12.1-h4a9f257_0 \n",
      "  gfortran_impl_lin~ pkgs/main::gfortran_impl_linux-64-11.~ --> conda-forge::gfortran_impl_linux-64-11.2.0-h7a446d4_16 \n",
      "  git                conda-forge::git-2.35.3-pl5321h04cb72~ --> pkgs/main::git-2.40.1-pl5340h36fbf9e_1 \n",
      "  gmp                                      6.2.1-h58526e2_0 --> 6.3.0-h59595ed_1 \n",
      "  icu                                       58.2-he6710b0_3 --> 73.1-h6a678d5_0 \n",
      "  julia                                    1.7.2-h35b96e5_1 --> 1.10.1-h764f291_0 \n",
      "  libclang                        10.0.1-default_hb85057a_2 --> 14.0.6-default_hc6dbbc7_1 \n",
      "  libcurl                                 7.88.1-h251f7ec_2 --> 8.7.1-h251f7ec_0 \n",
      "  libdeflate         conda-forge::libdeflate-1.10-h7f98852~ --> pkgs/main::libdeflate-1.17-h5eee18b_1 \n",
      "  libgfortran-ng     pkgs/main::libgfortran-ng-11.2.0-h003~ --> conda-forge::libgfortran-ng-13.2.0-h69a702a_0 \n",
      "  libgfortran5       pkgs/main::libgfortran5-11.2.0-h12345~ --> conda-forge::libgfortran5-13.2.0-ha4646dd_0 \n",
      "  libgit2                                  1.4.3-h4c07d5c_0 --> 1.7.2-h76de150_0 \n",
      "  libnghttp2                              1.52.0-h61bc06f_0 --> 1.58.0-h47da74e_1 \n",
      "  libssh2            conda-forge::libssh2-1.10.0-ha35d2d1_2 --> pkgs/main::libssh2-1.11.0-h251f7ec_0 \n",
      "  libtiff             conda-forge::libtiff-4.3.0-h0fcbabc_4 --> pkgs/main::libtiff-4.5.1-h6a678d5_0 \n",
      "  libutf8proc                              2.7.0-h7f98852_0 --> 2.8.0-h166bdaf_0 \n",
      "  libxkbcommon                             1.0.1-hfa300c1_0 --> 1.0.1-h5eee18b_1 \n",
      "  libxml2            conda-forge::libxml2-2.9.14-h22db469_0 --> pkgs/main::libxml2-2.10.4-hfdd30dd_2 \n",
      "  libxslt            conda-forge::libxslt-1.1.33-h8affb1d_4 --> pkgs/main::libxslt-1.1.37-h5eee18b_1 \n",
      "  mpfr                                     4.1.0-h9202a9a_1 --> 4.2.1-h9458935_1 \n",
      "  openssl                                  3.1.2-hd590300_0 --> 3.3.0-h4ab18f5_2 \n",
      "  pcre2                 conda-forge::pcre2-10.37-h032f7d1_0 --> pkgs/main::pcre2-10.42-hebb0a14_1 \n",
      "  pycosat            conda-forge::pycosat-0.6.4-py310h5764~ --> pkgs/main::pycosat-0.6.6-py38h5eee18b_1 \n",
      "  python                          3.8.13-ha86cf86_0_cpython --> 3.8.16-he550d4f_1_cpython \n",
      "  qt-main                                 5.15.2-h327a75a_6 --> 5.15.2-h53bd1ea_10 \n",
      "  r-base                                   4.2.0-h1ae530e_0 --> 4.3.1-h1ae530e_0 \n",
      "  sqlite                                  3.38.5-h4ff8645_0 --> 3.42.0-h2c6b66d_0 \n",
      "  xz                       conda-forge::xz-5.2.6-h166bdaf_0 --> pkgs/main::xz-5.4.6-h5eee18b_1 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  brotli-python      conda-forge::brotli-python-1.0.9-py31~ --> pkgs/main::brotli-python-1.0.9-py38h6a678d5_8 \n",
      "  conda              conda-forge::conda-23.3.1-py310hff520~ --> pkgs/main::conda-23.3.1-py38h06a4308_0 \n",
      "  ruamel.yaml        conda-forge::ruamel.yaml-0.17.32-py31~ --> pkgs/main::ruamel.yaml-0.17.21-py38h5eee18b_0 \n",
      "  ruamel.yaml.clib   conda-forge::ruamel.yaml.clib-0.2.7-p~ --> pkgs/main::ruamel.yaml.clib-0.2.6-py38h5eee18b_1 \n",
      "  zstandard          conda-forge::zstandard-0.19.0-py310h1~ --> pkgs/main::zstandard-0.19.0-py38h5eee18b_0 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  libmambapy                          1.4.2-py310h1428755_0 --> 1.4.2-py38h7fa060d_0 \n",
      "  mamba                               1.4.2-py310h51d5547_0 --> 1.4.2-py38haad2881_0 \n",
      "  python_abi                                   3.10-3_cp310 --> 3.8-4_cp38 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda config --set pip_interop_enabled true --file /localscratch/nwsja01/miniconda3/envs/stringAutoencoder/condarc-julia.yml` in root environment\n",
      "└ @ Conda /localscratch/nwsja01/.julia/packages/Conda/sDjAP/src/Conda.jl:181\n",
      "┌ Info: Running `pip install asjp` in root environment\n",
      "└ @ Conda /localscratch/nwsja01/.julia/packages/Conda/sDjAP/src/Conda.jl:669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting asjp\n",
      "  Obtaining dependency information for asjp from https://files.pythonhosted.org/packages/d8/b3/3af44aead0869c857ccf21557ec514f45e803a7281ab626db7926d5d85fe/asjp-0.0.2-py3-none-any.whl.metadata\n",
      "  Downloading asjp-0.0.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting ipatok>=0.2 (from asjp)\n",
      "  Obtaining dependency information for ipatok>=0.2 from https://files.pythonhosted.org/packages/6a/23/6310fb6f98f50eb00bcb1e593f3d91ff04e1e8b6eeac2d077d3cdbcf57a3/ipatok-0.4.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading ipatok-0.4.2-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Using cached asjp-0.0.2-py3-none-any.whl (10 kB)\n",
      "Downloading ipatok-0.4.2-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: ipatok, asjp\n",
      "Successfully installed asjp-0.0.2 ipatok-0.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda ─→ `/localscratch/nwsja01/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/51cab8e982c5b598eea9c8ceaced4b58d9dd37c9/build.log`\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m PyCall → `/localscratch/nwsja01/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/9816a3826b0ebf49ab4926e2b18842ad8b5c8f04/build.log`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39mPyCall\n",
      "  1 dependency successfully precompiled in 11 seconds. 271 already precompiled.\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda → `/localscratch/nwsja01/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/51cab8e982c5b598eea9c8ceaced4b58d9dd37c9/build.log`\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m RCall → `/localscratch/nwsja01/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/846b2aab2d312fda5e7b099fc217c661e8fae27e/build.log`\n"
     ]
    },
    {
     "ename": "PyCall.PyError",
     "evalue": "PyError (PyImport_ImportModule\n\nThe Python package asjp could not be imported by pyimport. Usually this means\nthat you did not install asjp in the Python version being used by PyCall.\n\nPyCall is currently configured to use the Julia-specific Python distribution\ninstalled by the Conda.jl package.  To install the asjp module, you can\nuse `pyimport_conda(\"asjp\", PKG)`, where PKG is the Anaconda\npackage that contains the module asjp, or alternatively you can use the\nConda package directly (via `using Conda` followed by `Conda.add` etcetera).\n\nAlternatively, if you want to use a different Python distribution on your\nsystem, such as a system-wide Python (as opposed to the Julia-specific Python),\nyou can re-configure PyCall with that Python.   As explained in the PyCall\ndocumentation, set ENV[\"PYTHON\"] to the path/name of the python executable\nyou want to use, run Pkg.build(\"PyCall\"), and re-launch Julia.\n\n) <class 'ModuleNotFoundError'>\nModuleNotFoundError(\"No module named 'asjp'\")\n",
     "output_type": "error",
     "traceback": [
      "PyError (PyImport_ImportModule\n",
      "\n",
      "The Python package asjp could not be imported by pyimport. Usually this means\n",
      "that you did not install asjp in the Python version being used by PyCall.\n",
      "\n",
      "PyCall is currently configured to use the Julia-specific Python distribution\n",
      "installed by the Conda.jl package.  To install the asjp module, you can\n",
      "use `pyimport_conda(\"asjp\", PKG)`, where PKG is the Anaconda\n",
      "package that contains the module asjp, or alternatively you can use the\n",
      "Conda package directly (via `using Conda` followed by `Conda.add` etcetera).\n",
      "\n",
      "Alternatively, if you want to use a different Python distribution on your\n",
      "system, such as a system-wide Python (as opposed to the Julia-specific Python),\n",
      "you can re-configure PyCall with that Python.   As explained in the PyCall\n",
      "documentation, set ENV[\"PYTHON\"] to the path/name of the python executable\n",
      "you want to use, run Pkg.build(\"PyCall\"), and re-launch Julia.\n",
      "\n",
      ") <class 'ModuleNotFoundError'>\n",
      "ModuleNotFoundError(\"No module named 'asjp'\")\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] pyimport(name::String)\n",
      "   @ PyCall /localscratch/nwsja01/.julia/packages/PyCall/1gn3u/src/PyCall.jl:558\n",
      " [2] top-level scope\n",
      "   @ /localscratch/nwsja01/projects/msa_vs_cognates/code/create_msas.ipynb:31"
     ]
    }
   ],
   "source": [
    "# Julia Packages\n",
    "using CSV\n",
    "using DataFrames\n",
    "using MCPhyloTree\n",
    "using ProgressMeter\n",
    "using Pipe\n",
    "using ArgCheck\n",
    "using Base.Threads\n",
    "using StatsPlots\n",
    "using StatsBase\n",
    "using RCall\n",
    "\n",
    "# Plotting backend\n",
    "plotlyjs()\n",
    "\n",
    "# Include external scripts\n",
    "include(\"needlemanWunsch.jl\")\n",
    "\n",
    "# Conda and R setup\n",
    "using Conda\n",
    "Conda.add(\"r-phangorn\")\n",
    "\n",
    "ENV[\"R_HOME\"] = \"*\"\n",
    "Pkg.build(\"RCall\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>435691×13 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">435666 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">db</th><th style = \"text-align: left;\">ID</th><th style = \"text-align: left;\">Language_ID</th><th style = \"text-align: left;\">Parameter_ID</th><th style = \"text-align: left;\">Segments</th><th style = \"text-align: left;\">Glottolog_Name</th><th style = \"text-align: left;\">Glottocode</th><th style = \"text-align: left;\">Family</th><th style = \"text-align: left;\">Concepticon_ID</th><th style = \"text-align: left;\">Concepticon_Gloss</th><th style = \"text-align: left;\">Cognateset_ID</th><th style = \"text-align: left;\">cc</th><th style = \"text-align: left;\">ASJP</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String31\" style = \"text-align: left;\">String31</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Union{Missing, String}\" style = \"text-align: left;\">String?</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Union{Missing, String}\" style = \"text-align: left;\">String?</th><th title = \"String\" style = \"text-align: left;\">String</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-1_hand-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">1_hand</td><td style = \"text-align: left;\">n u m a</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1277</td><td style = \"text-align: left;\">HAND</td><td style = \"text-align: left;\">hand-1</td><td style = \"text-align: left;\">abvdoceanic:hand-1</td><td style = \"text-align: left;\">numa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-1_hand-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">1_hand</td><td style = \"text-align: left;\">n u m a</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1277</td><td style = \"text-align: left;\">HAND</td><td style = \"text-align: left;\">hand-66</td><td style = \"text-align: left;\">abvdoceanic:hand-66</td><td style = \"text-align: left;\">numa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-2_left-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">2_left</td><td style = \"text-align: left;\">t o r o r o n a</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">244</td><td style = \"text-align: left;\">LEFT</td><td style = \"text-align: left;\">left-66</td><td style = \"text-align: left;\">abvdoceanic:left-66</td><td style = \"text-align: left;\">tororona</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-3_right-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">3_right</td><td style = \"text-align: left;\">m a t oː</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1019</td><td style = \"text-align: left;\">RIGHT</td><td style = \"text-align: left;\">right-5</td><td style = \"text-align: left;\">abvdoceanic:right-5</td><td style = \"text-align: left;\">mato</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-3_right-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">3_right</td><td style = \"text-align: left;\">m a t oː</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1019</td><td style = \"text-align: left;\">RIGHT</td><td style = \"text-align: left;\">right-13</td><td style = \"text-align: left;\">abvdoceanic:right-13</td><td style = \"text-align: left;\">mato</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-5_towalk-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">5_towalk</td><td style = \"text-align: left;\">v a n a v i d o</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1443</td><td style = \"text-align: left;\">WALK</td><td style = \"text-align: left;\">towalk-2</td><td style = \"text-align: left;\">abvdoceanic:towalk-2</td><td style = \"text-align: left;\">vanavido</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-5_towalk-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">5_towalk</td><td style = \"text-align: left;\">v a n a v i d o</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1443</td><td style = \"text-align: left;\">WALK</td><td style = \"text-align: left;\">towalk-64</td><td style = \"text-align: left;\">abvdoceanic:towalk-64</td><td style = \"text-align: left;\">vanavido</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-6_roadpath-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">6_roadpath</td><td style = \"text-align: left;\">s a n a n a</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">2457</td><td style = \"text-align: left;\">PATH OR ROAD</td><td style = \"text-align: left;\">roadpath-1</td><td style = \"text-align: left;\">abvdoceanic:roadpath-1</td><td style = \"text-align: left;\">sanana</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-7_tocome-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">7_tocome</td><td style = \"text-align: left;\">m a</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1446</td><td style = \"text-align: left;\">COME</td><td style = \"text-align: left;\">tocome-1</td><td style = \"text-align: left;\">abvdoceanic:tocome-1</td><td style = \"text-align: left;\">ma</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-7_tocome-2</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">7_tocome</td><td style = \"text-align: left;\">t a i + m a</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1446</td><td style = \"text-align: left;\">COME</td><td style = \"text-align: left;\">tocome-1</td><td style = \"text-align: left;\">abvdoceanic:tocome-1</td><td style = \"text-align: left;\">taima</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-9_toswim-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">9_toswim</td><td style = \"text-align: left;\">s uː</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1439</td><td style = \"text-align: left;\">SWIM</td><td style = \"text-align: left;\">toswim-12</td><td style = \"text-align: left;\">abvdoceanic:toswim-12</td><td style = \"text-align: left;\">su</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-12_skin-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">12_skin</td><td style = \"text-align: left;\">k a b u n u</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">763</td><td style = \"text-align: left;\">SKIN</td><td style = \"text-align: left;\">skin-98</td><td style = \"text-align: left;\">abvdoceanic:skin-98</td><td style = \"text-align: left;\">kabunu</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">abvdoceanic</td><td style = \"text-align: left;\">Banoni_4-13_back-1</td><td style = \"text-align: left;\">Banoni_4</td><td style = \"text-align: left;\">13_back</td><td style = \"text-align: left;\">ts u gʱ i</td><td style = \"text-align: left;\">Bannoni</td><td style = \"text-align: left;\">bann1247</td><td style = \"text-align: left;\">Austronesian</td><td style = \"text-align: right;\">1291</td><td style = \"text-align: left;\">BACK</td><td style = \"text-align: left;\">back-12</td><td style = \"text-align: left;\">abvdoceanic:back-12</td><td style = \"text-align: left;\">tsugi</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435680</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">OldChinese-282_thepulsebeans-1</td><td style = \"text-align: left;\">OldChinese</td><td style = \"text-align: left;\">282_thepulsebeans</td><td style = \"text-align: left;\">s tʰ u k</td><td style = \"text-align: left;\">Old Chinese</td><td style = \"text-align: left;\">oldc1244</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">832</td><td style = \"text-align: left;\">BEAN</td><td style = \"text-align: left;\">120</td><td style = \"text-align: left;\">zhangrgyalrong:120</td><td style = \"text-align: left;\">sthuk</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435681</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">CogtseSitu-282_thepulsebeans-1</td><td style = \"text-align: left;\">CogtseSitu</td><td style = \"text-align: left;\">282_thepulsebeans</td><td style = \"text-align: left;\">t ɐ + s t ō k</td><td style = \"text-align: left;\">Maerkang</td><td style = \"text-align: left;\">maer1238</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">832</td><td style = \"text-align: left;\">BEAN</td><td style = \"text-align: left;\">120</td><td style = \"text-align: left;\">zhangrgyalrong:120</td><td style = \"text-align: left;\">tastok</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435682</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">BragbarSitu-282_thepulsebeans-1</td><td style = \"text-align: left;\">BragbarSitu</td><td style = \"text-align: left;\">282_thepulsebeans</td><td style = \"text-align: left;\">t a + s t ɐ̄ k</td><td style = \"text-align: left;\">Maerkang</td><td style = \"text-align: left;\">maer1238</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">832</td><td style = \"text-align: left;\">BEAN</td><td style = \"text-align: left;\">120</td><td style = \"text-align: left;\">zhangrgyalrong:120</td><td style = \"text-align: left;\">tastak</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435683</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">Japhug-282_thepulsebeans-1</td><td style = \"text-align: left;\">Japhug</td><td style = \"text-align: left;\">282_thepulsebeans</td><td style = \"text-align: left;\">s t o ʁ</td><td style = \"text-align: left;\">dGonpa</td><td style = \"text-align: left;\">dgon1234</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">832</td><td style = \"text-align: left;\">BEAN</td><td style = \"text-align: left;\">120</td><td style = \"text-align: left;\">zhangrgyalrong:120</td><td style = \"text-align: left;\">stoX</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435684</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">OldChinese-305_thehorse-1</td><td style = \"text-align: left;\">OldChinese</td><td style = \"text-align: left;\">305_thehorse</td><td style = \"text-align: left;\">mˤ r a ʔ</td><td style = \"text-align: left;\">Old Chinese</td><td style = \"text-align: left;\">oldc1244</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">615</td><td style = \"text-align: left;\">HORSE</td><td style = \"text-align: left;\">121</td><td style = \"text-align: left;\">zhangrgyalrong:121</td><td style = \"text-align: left;\">mra7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435685</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">CogtseSitu-305_thehorse-1</td><td style = \"text-align: left;\">CogtseSitu</td><td style = \"text-align: left;\">305_thehorse</td><td style = \"text-align: left;\">m b r ō</td><td style = \"text-align: left;\">Maerkang</td><td style = \"text-align: left;\">maer1238</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">615</td><td style = \"text-align: left;\">HORSE</td><td style = \"text-align: left;\">121</td><td style = \"text-align: left;\">zhangrgyalrong:121</td><td style = \"text-align: left;\">mbro</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435686</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">BragbarSitu-305_thehorse-1</td><td style = \"text-align: left;\">BragbarSitu</td><td style = \"text-align: left;\">305_thehorse</td><td style = \"text-align: left;\">m b r ō</td><td style = \"text-align: left;\">Maerkang</td><td style = \"text-align: left;\">maer1238</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">615</td><td style = \"text-align: left;\">HORSE</td><td style = \"text-align: left;\">121</td><td style = \"text-align: left;\">zhangrgyalrong:121</td><td style = \"text-align: left;\">mbro</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435687</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">Japhug-305_thehorse-1</td><td style = \"text-align: left;\">Japhug</td><td style = \"text-align: left;\">305_thehorse</td><td style = \"text-align: left;\">m b r o</td><td style = \"text-align: left;\">dGonpa</td><td style = \"text-align: left;\">dgon1234</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">615</td><td style = \"text-align: left;\">HORSE</td><td style = \"text-align: left;\">121</td><td style = \"text-align: left;\">zhangrgyalrong:121</td><td style = \"text-align: left;\">mbro</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435688</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">OldChinese-199_therabbithare-1</td><td style = \"text-align: left;\">OldChinese</td><td style = \"text-align: left;\">199_therabbithare</td><td style = \"text-align: left;\">l̥ˤ a s</td><td style = \"text-align: left;\">Old Chinese</td><td style = \"text-align: left;\">oldc1244</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">2345</td><td style = \"text-align: left;\">LEPORID (RABBIT OR HARE)</td><td style = \"text-align: left;\">122</td><td style = \"text-align: left;\">zhangrgyalrong:122</td><td style = \"text-align: left;\">las</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435689</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">CogtseSitu-199_therabbithare-1</td><td style = \"text-align: left;\">CogtseSitu</td><td style = \"text-align: left;\">199_therabbithare</td><td style = \"text-align: left;\">k a + l ā</td><td style = \"text-align: left;\">Maerkang</td><td style = \"text-align: left;\">maer1238</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">2345</td><td style = \"text-align: left;\">LEPORID (RABBIT OR HARE)</td><td style = \"text-align: left;\">122</td><td style = \"text-align: left;\">zhangrgyalrong:122</td><td style = \"text-align: left;\">kala</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435690</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">BragbarSitu-199_therabbithare-1</td><td style = \"text-align: left;\">BragbarSitu</td><td style = \"text-align: left;\">199_therabbithare</td><td style = \"text-align: left;\">k a + l i ɛ̄</td><td style = \"text-align: left;\">Maerkang</td><td style = \"text-align: left;\">maer1238</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">2345</td><td style = \"text-align: left;\">LEPORID (RABBIT OR HARE)</td><td style = \"text-align: left;\">122</td><td style = \"text-align: left;\">zhangrgyalrong:122</td><td style = \"text-align: left;\">kaliE</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">435691</td><td style = \"text-align: left;\">zhangrgyalrong</td><td style = \"text-align: left;\">Japhug-199_therabbithare-1</td><td style = \"text-align: left;\">Japhug</td><td style = \"text-align: left;\">199_therabbithare</td><td style = \"text-align: left;\">q a + l a</td><td style = \"text-align: left;\">dGonpa</td><td style = \"text-align: left;\">dgon1234</td><td style = \"text-align: left;\">Sino-Tibetan</td><td style = \"text-align: right;\">2345</td><td style = \"text-align: left;\">LEPORID (RABBIT OR HARE)</td><td style = \"text-align: left;\">122</td><td style = \"text-align: left;\">zhangrgyalrong:122</td><td style = \"text-align: left;\">qala</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& db & ID & Language\\_ID & Parameter\\_ID & Segments & \\\\\n",
       "\t\\hline\n",
       "\t& String31 & String & String & String & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & abvdoceanic & Banoni\\_4-1\\_hand-1 & Banoni\\_4 & 1\\_hand & n u m a & $\\dots$ \\\\\n",
       "\t2 & abvdoceanic & Banoni\\_4-1\\_hand-1 & Banoni\\_4 & 1\\_hand & n u m a & $\\dots$ \\\\\n",
       "\t3 & abvdoceanic & Banoni\\_4-2\\_left-1 & Banoni\\_4 & 2\\_left & t o r o r o n a & $\\dots$ \\\\\n",
       "\t4 & abvdoceanic & Banoni\\_4-3\\_right-1 & Banoni\\_4 & 3\\_right & m a t oː & $\\dots$ \\\\\n",
       "\t5 & abvdoceanic & Banoni\\_4-3\\_right-1 & Banoni\\_4 & 3\\_right & m a t oː & $\\dots$ \\\\\n",
       "\t6 & abvdoceanic & Banoni\\_4-5\\_towalk-1 & Banoni\\_4 & 5\\_towalk & v a n a v i d o & $\\dots$ \\\\\n",
       "\t7 & abvdoceanic & Banoni\\_4-5\\_towalk-1 & Banoni\\_4 & 5\\_towalk & v a n a v i d o & $\\dots$ \\\\\n",
       "\t8 & abvdoceanic & Banoni\\_4-6\\_roadpath-1 & Banoni\\_4 & 6\\_roadpath & s a n a n a & $\\dots$ \\\\\n",
       "\t9 & abvdoceanic & Banoni\\_4-7\\_tocome-1 & Banoni\\_4 & 7\\_tocome & m a & $\\dots$ \\\\\n",
       "\t10 & abvdoceanic & Banoni\\_4-7\\_tocome-2 & Banoni\\_4 & 7\\_tocome & t a i + m a & $\\dots$ \\\\\n",
       "\t11 & abvdoceanic & Banoni\\_4-9\\_toswim-1 & Banoni\\_4 & 9\\_toswim & s uː & $\\dots$ \\\\\n",
       "\t12 & abvdoceanic & Banoni\\_4-12\\_skin-1 & Banoni\\_4 & 12\\_skin & k a b u n u & $\\dots$ \\\\\n",
       "\t13 & abvdoceanic & Banoni\\_4-13\\_back-1 & Banoni\\_4 & 13\\_back & ts u gʱ i & $\\dots$ \\\\\n",
       "\t14 & abvdoceanic & Banoni\\_4-14\\_belly-1 & Banoni\\_4 & 14\\_belly & k o b i & $\\dots$ \\\\\n",
       "\t15 & abvdoceanic & Banoni\\_4-15\\_bone-1 & Banoni\\_4 & 15\\_bone & s i p a n a & $\\dots$ \\\\\n",
       "\t16 & abvdoceanic & Banoni\\_4-16\\_intestines-1 & Banoni\\_4 & 16\\_intestines & k o r e & $\\dots$ \\\\\n",
       "\t17 & abvdoceanic & Banoni\\_4-17\\_liver-1 & Banoni\\_4 & 17\\_liver & d a t e & $\\dots$ \\\\\n",
       "\t18 & abvdoceanic & Banoni\\_4-18\\_breast-1 & Banoni\\_4 & 18\\_breast & s u & $\\dots$ \\\\\n",
       "\t19 & abvdoceanic & Banoni\\_4-21\\_tothink-1 & Banoni\\_4 & 21\\_tothink & v a r e k a n a & $\\dots$ \\\\\n",
       "\t20 & abvdoceanic & Banoni\\_4-25\\_neck-1 & Banoni\\_4 & 25\\_neck & k o k o r o m o & $\\dots$ \\\\\n",
       "\t21 & abvdoceanic & Banoni\\_4-26\\_hair-1 & Banoni\\_4 & 26\\_hair & p u n u & $\\dots$ \\\\\n",
       "\t22 & abvdoceanic & Banoni\\_4-27\\_nose-1 & Banoni\\_4 & 27\\_nose & v i v i ts i & $\\dots$ \\\\\n",
       "\t23 & abvdoceanic & Banoni\\_4-27\\_nose-2 & Banoni\\_4 & 27\\_nose & v i s u & $\\dots$ \\\\\n",
       "\t24 & abvdoceanic & Banoni\\_4-28\\_tobreathe-1 & Banoni\\_4 & 28\\_tobreathe & v a s a & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m435691×13 DataFrame\u001b[0m\n",
       "\u001b[1m    Row \u001b[0m│\u001b[1m db             \u001b[0m\u001b[1m ID                              \u001b[0m\u001b[1m Language_ID \u001b[0m\u001b[1m Parame\u001b[0m ⋯\n",
       "        │\u001b[90m String31       \u001b[0m\u001b[90m String                          \u001b[0m\u001b[90m String      \u001b[0m\u001b[90m String\u001b[0m ⋯\n",
       "────────┼───────────────────────────────────────────────────────────────────────\n",
       "      1 │ abvdoceanic     Banoni_4-1_hand-1                Banoni_4     1_hand ⋯\n",
       "      2 │ abvdoceanic     Banoni_4-1_hand-1                Banoni_4     1_hand\n",
       "      3 │ abvdoceanic     Banoni_4-2_left-1                Banoni_4     2_left\n",
       "      4 │ abvdoceanic     Banoni_4-3_right-1               Banoni_4     3_righ\n",
       "      5 │ abvdoceanic     Banoni_4-3_right-1               Banoni_4     3_righ ⋯\n",
       "      6 │ abvdoceanic     Banoni_4-5_towalk-1              Banoni_4     5_towa\n",
       "      7 │ abvdoceanic     Banoni_4-5_towalk-1              Banoni_4     5_towa\n",
       "      8 │ abvdoceanic     Banoni_4-6_roadpath-1            Banoni_4     6_road\n",
       "   ⋮    │       ⋮                        ⋮                      ⋮              ⋱\n",
       " 435685 │ zhangrgyalrong  CogtseSitu-305_thehorse-1        CogtseSitu   305_th ⋯\n",
       " 435686 │ zhangrgyalrong  BragbarSitu-305_thehorse-1       BragbarSitu  305_th\n",
       " 435687 │ zhangrgyalrong  Japhug-305_thehorse-1            Japhug       305_th\n",
       " 435688 │ zhangrgyalrong  OldChinese-199_therabbithare-1   OldChinese   199_th\n",
       " 435689 │ zhangrgyalrong  CogtseSitu-199_therabbithare-1   CogtseSitu   199_th ⋯\n",
       " 435690 │ zhangrgyalrong  BragbarSitu-199_therabbithare-1  BragbarSitu  199_th\n",
       " 435691 │ zhangrgyalrong  Japhug-199_therabbithare-1       Japhug       199_th\n",
       "\u001b[36m                                              10 columns and 435676 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wl = @pipe CSV.File(\"../data/lexibank_wordlist.csv\") |> \n",
    "    DataFrame |>\n",
    "    dropmissing(_, [:ASJP, :Cognateset_ID]) |>\n",
    "    filter(x -> x.ASJP != \"\", _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60-element Vector{String31}:\n",
       " \"abvdoceanic\"\n",
       " \"bdpa\"\n",
       " \"birchallchapacuran\"\n",
       " \"bodtkhobwa\"\n",
       " \"bowernpny\"\n",
       " \"cals\"\n",
       " \"carvalhopurus\"\n",
       " \"chaconarawakan\"\n",
       " \"chaconbaniwa\"\n",
       " \"chaconcolumbian\"\n",
       " ⋮\n",
       " \"starostinhmongmien\"\n",
       " \"starostinkaren\"\n",
       " \"starostintujia\"\n",
       " \"syrjaenenuralic\"\n",
       " \"utoaztecan\"\n",
       " \"walworthpolynesian\"\n",
       " \"wichmannmixezoquean\"\n",
       " \"yanglalo\"\n",
       " \"zhangrgyalrong\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets\n",
    "dbs = unique(wl.db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMI Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pmiStar (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function pmiStar(w1::Union{Missing,String}, w2::Union{Missing,String}, p::NW)\n",
    "    if ismissing(w1) || ismissing(w2)\n",
    "        return missing\n",
    "    end\n",
    "    v1 = split(w1,\"-\")\n",
    "    v2 = split(w2,\"-\")\n",
    "    scores = Vector{Float64}(undef, length(v1)*length(v2))\n",
    "    counter = 1\n",
    "    for x in v1\n",
    "        for y in v2\n",
    "            @inbounds scores[counter] = nw(x, y, p)\n",
    "            counter += 1\n",
    "        end\n",
    "    end\n",
    "    maximum(scores)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree and Matrix Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_alignment (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function dercPMI(\n",
    "    i::Int,\n",
    "    j::Int,\n",
    "    p::NW,\n",
    "    dMtx::Matrix{Union{Missing, String}} = dMtx,\n",
    "    maxSim::Float64 = maxSim,\n",
    "    minSim::Float64 = minSim,\n",
    ")\n",
    "    defined1 = findall(.!ismissing.(dMtx[i, :]))\n",
    "    defined2 = findall(.!ismissing.(dMtx[j, :]))\n",
    "    definedBoth = intersect(defined1, defined2)\n",
    "    nBoth = length(definedBoth)\n",
    "    if nBoth == 0\n",
    "        return missing\n",
    "    end\n",
    "    dg = Vector{Float64}(undef, nBoth)\n",
    "    for (k, c) in enumerate(definedBoth)\n",
    "        dg[k] = pmiStar(dMtx[i, c], dMtx[j, c], p)\n",
    "    end\n",
    "    nOffD = length(defined1) * length(defined2) - nBoth\n",
    "    offDg = Vector{Float64}(undef, nOffD)\n",
    "    counter = 1\n",
    "    for k1 in defined1\n",
    "        w1 = dMtx[i, k1]\n",
    "        for k2 in defined2\n",
    "            if k1 != k2\n",
    "                w2 = dMtx[j, k2]\n",
    "                @inbounds offDg[counter] = pmiStar(w1, w2, p)\n",
    "                counter += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    ranks = Vector{Float64}(undef, nBoth)\n",
    "    for k = 1:nBoth\n",
    "        @inbounds x = dg[k]\n",
    "        @inbounds ranks[k] = geomean(1 .+ (sum(offDg .> x):sum(offDg .>= x)))\n",
    "    end\n",
    "    stc = mean(-log.(ranks ./ (1 + nOffD)))\n",
    "    sim = (stc - 1) * sqrt(nBoth)\n",
    "    (maxSim - sim) / (maxSim - minSim)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Takes two gapped strings and returns the hamming distance between\n",
    "them. Positions containing a gap in at least one string are ignored.\n",
    "\"\"\"\n",
    "function sHamming(al)\n",
    "    ds = []\n",
    "    for i in 1:size(al, 1)\n",
    "        s1, s2 = al[i, :]\n",
    "        if !ismissing(s1) && !ismissing(s2)\n",
    "            push!(\n",
    "                ds,\n",
    "                Int(s1 != s2)\n",
    "            )\n",
    "        end\n",
    "    end\n",
    "    mean(ds)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Takes a pairwise alignment (i.e. a pair of gapped strings with identical length)\n",
    "as input and returns a matrix representation M as output.\n",
    "The matrix M is defined as M[i,j] = 1 if x[i] is matched with y[j]\n",
    "in the alignment, 0 else (where x,y are the two ungapped strings to be aligned).\n",
    "\"\"\"\n",
    "\n",
    "function algnMatrix(al)\n",
    "    w1 = filter(x -> !ismissing(x), al[:, 1])\n",
    "    w2 = filter(x -> !ismissing(x), al[:, 2])\n",
    "    dm = zeros(Int, length(w1), length(w2))\n",
    "    i, j = 1, 1\n",
    "    for k in 1:size(al, 1)\n",
    "        s1, s2 = al[k, :]\n",
    "        if !ismissing(s1)\n",
    "            if !ismissing(s2)\n",
    "                dm[i, j] += 1\n",
    "                i += 1\n",
    "                j += 1\n",
    "            else\n",
    "                i += 1\n",
    "            end\n",
    "        else\n",
    "            j += 1\n",
    "        end\n",
    "    end\n",
    "    dm\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Takes a list of sequences and returns a library in the sense of the\n",
    "T-Coffee algorithm. A library is a dictionary with sequence pairs\n",
    "as keys and pairwise alignments in matrix format as columns.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "function createLibrary(words; pmiPar::NW=pmiPar)\n",
    "    library = Dict{Tuple{String, String}, Tuple{Matrix{Int}, Float64}}()\n",
    "    library_lock = ReentrantLock()\n",
    "    uwords = unique(words)\n",
    "    @threads for w1 in uwords\n",
    "        for w2 in uwords\n",
    "            if (w2, w1) in keys(library)\n",
    "                lock(library_lock)\n",
    "                try\n",
    "                    x = library[w2, w1]\n",
    "                    library[w1, w2] = (Matrix{Int}(x[1]'), x[2])\n",
    "                finally\n",
    "                    unlock(library_lock)\n",
    "                end\n",
    "            else\n",
    "                al = nwAlign(w1, w2, pmiPar)[1]\n",
    "                lock(library_lock)\n",
    "                try\n",
    "                    library[w1, w2] = (algnMatrix(al), 1 - sHamming(al))\n",
    "                finally\n",
    "                    unlock(library_lock)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return library\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Takes a list of sequences and returns an extended library in the\n",
    "sense of the T-Coffee algorithm. An extended library is a dictionary with\n",
    "sequence pairs as keys and a score matrix as values.\n",
    "For a pair of sequences x,y and a corresponding score matrix M,\n",
    "M[i,j] is the score for aligning x[i] with y[j].\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "function createExtendedLibrary(words; pmiPar::NW=pmiPar)\n",
    "    uwords = unique(words)\n",
    "    library = createLibrary(uwords; pmiPar=pmiPar)\n",
    "    extLibrary = Dict{Tuple{String, String}, Matrix{Float32}}()\n",
    "    extLibrary_lock = ReentrantLock()\n",
    "\n",
    "    # Precompute some values to avoid repeated computation in the loop\n",
    "    word_pairs = [(i, j, uwords[i], uwords[j]) for i in 1:length(uwords), j in 1:length(uwords) if i <= j]\n",
    "\n",
    "    @threads for (i, j, w1, w2) in word_pairs\n",
    "        n, m = length.(collect.([w1, w2]))\n",
    "        dm = zeros(Float32, n, m)\n",
    "        \n",
    "        for w3 in words\n",
    "            a1, s1 = library[w1, w3]\n",
    "            a2, s2 = library[w3, w2]\n",
    "            a1, a2 = Matrix{Float32}(a1), Matrix{Float32}(a2)\n",
    "            dm += (s1 + s2) * (a1 * a2)\n",
    "        end\n",
    "    \n",
    "        lock(extLibrary_lock)\n",
    "        try\n",
    "            extLibrary[w1, w2] = dm\n",
    "            extLibrary[w2, w1] = Matrix{Float32}(dm')\n",
    "        finally\n",
    "            unlock(extLibrary_lock)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return extLibrary\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Returns the index of gappedString[i] in the\n",
    "ungapped version thereof.\n",
    "If gappedString[i] is a gap, returns -1\n",
    "\"\"\"\n",
    "\n",
    "function pos(alVector, i)\n",
    "    if ismissing(alVector[i])\n",
    "        return -1\n",
    "    end\n",
    "    return i - sum(ismissing.(alVector[1:i]))\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Needleman-Wunsch alignment of two aligned blocks b1 and b2,\n",
    "using the scores in the extended library lib.\n",
    "\"\"\"\n",
    "function nwBlock(al1, al2, extLibrary)\n",
    "    # Prepare words1 and words2 using comprehensions\n",
    "    words1 = [join(filter(x -> !ismissing(x), al1[:, i]), \"\") for i in 1:size(al1, 2)]\n",
    "    words2 = [join(filter(x -> !ismissing(x), al2[:, i]), \"\") for i in 1:size(al2, 2)]\n",
    "\n",
    "    n, m = size(al1, 1), size(al2, 1)\n",
    "    dp = zeros(n + 1, m + 1)\n",
    "    pointers = zeros(Int, n + 1, m + 1)\n",
    "\n",
    "    # Initialize first row and column of pointers\n",
    "    pointers[1, 2:end] .= 3  # All deletions\n",
    "    pointers[2:end, 1] .= 2  # All insertions\n",
    "\n",
    "    match_cache = Dict{Tuple{Int, Int}, Float64}()\n",
    "\n",
    "    for i in 2:(n + 1)\n",
    "        for j in 2:(m + 1)\n",
    "            insert = dp[i-1, j]\n",
    "            delet = dp[i, j-1]\n",
    "            match = dp[i-1, j-1]\n",
    "\n",
    "            match_val = 0.0\n",
    "            for k in 1:length(words1)\n",
    "                for l in 1:length(words2)\n",
    "                    if !ismissing(al1[i-1, k]) && !ismissing(al2[j-1, l])\n",
    "                        pos1 = i - 1\n",
    "                        pos2 = j - 1\n",
    "                        w1, w2 = words1[k], words2[l]\n",
    "\n",
    "                        if haskey(match_cache, (pos1, pos2))\n",
    "                            match_val = match_cache[(pos1, pos2)]\n",
    "                        else\n",
    "                            if pos1 <= size(extLibrary[w1, w2], 1) && pos2 <= size(extLibrary[w1, w2], 2)\n",
    "                                match_val += extLibrary[w1, w2][pos1, pos2]\n",
    "                                match_cache[(pos1, pos2)] = match_val\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            match += match_val\n",
    "\n",
    "            # Update dp and pointers\n",
    "            dp[i, j], pointers[i, j] = maximum([(match, 1), (insert, 2), (delet, 3)])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Traceback to find the alignment path\n",
    "    i, j = n + 1, m + 1\n",
    "    indices = Vector{Tuple{Int, Int}}()\n",
    "    while i > 1 || j > 1\n",
    "        p = pointers[i, j]\n",
    "        if p == 1\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "            pushfirst!(indices, (i, j))\n",
    "        elseif p == 2\n",
    "            i -= 1\n",
    "            pushfirst!(indices, (i, -1))\n",
    "        else\n",
    "            j -= 1\n",
    "            pushfirst!(indices, (-1, j))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Initialize alNew array\n",
    "    alNew = Array{Union{Char, Missing}}(missing, length(indices), size(al1, 2) + size(al2, 2))\n",
    "\n",
    "    # Fill alNew with aligned sequences\n",
    "    for (k, (i, j)) in enumerate(indices)\n",
    "        if i == -1\n",
    "            x1 = fill(missing, size(al1, 2))\n",
    "        else\n",
    "            x1 = al1[i, :]\n",
    "        end\n",
    "        if j == -1\n",
    "            x2 = fill(missing, size(al2, 2))\n",
    "        else\n",
    "            x2 = al2[j, :]\n",
    "        end\n",
    "        alNew[k, :] = vcat(x1, x2)\n",
    "    end\n",
    "\n",
    "    alNew\n",
    "end\n",
    "\n",
    "\n",
    "function tCoffee(guide_tree; pmiPar::NW=pmiPar)\n",
    "    words = [string(split(x.name, \":\")[2]) for x in get_leaves(guide_tree)]\n",
    "    taxa = [string(split(x.name, \":\")[1]) for x in get_leaves(guide_tree)]\n",
    "    extLibrary = createExtendedLibrary(words; pmiPar=pmiPar)\n",
    "    alHistory = Dict()\n",
    "    nums = Dict()\n",
    "    for nd in post_order(guide_tree)\n",
    "        if length(nd.children) == 0\n",
    "            w = string(split(nd.name, \":\")[2])\n",
    "            alHistory[nd.num] = reshape(collect(w), :, 1)\n",
    "            nums[nd.num] = [nd.num]\n",
    "        elseif length(nd.children) == 1\n",
    "            alHistory[nd.num] = alHistory[nd.children[1].num]\n",
    "            nums[nd.num] = [nums[nd.children[1].num]]\n",
    "        else\n",
    "            ch1, ch2 = nd.children\n",
    "            al1 = alHistory[ch1.num]\n",
    "            al2 = alHistory[ch2.num]\n",
    "            nums1 = nums[ch1.num]\n",
    "            nums2 = nums[ch2.num]\n",
    "            alHistory[nd.num] = nwBlock(al1, al2, extLibrary)\n",
    "            nums[nd.num] = vcat(nums1, nums2)\n",
    "        end\n",
    "    end\n",
    "    df = DataFrame(permutedims(alHistory[guide_tree.num]), :auto)\n",
    "    insertcols!(df, 1, :language => taxa)\n",
    "    df\n",
    "end\n",
    "\n",
    "\n",
    "function create_guide_tree(data::DataFrame; tree::GeneralNode=tree)\n",
    "    words2lang = @pipe data |>\n",
    "        zip(_.ASJP, _.Glottocode) \n",
    "    words = first.(words2lang)\n",
    "    taxa = last.(values(words2lang))\n",
    "    unique_taxa = unique(taxa)\n",
    "    guide_tree = deepcopy(tree)\n",
    "    for nd in post_order(guide_tree)\n",
    "        if nd.nchild == 0 && nd.name ∉ unique_taxa && !isroot(nd)\n",
    "            mother = get_mother(nd)\n",
    "            remove_child!(mother, nd)\n",
    "        end\n",
    "    end\n",
    "    while guide_tree.nchild == 1\n",
    "        guide_tree = guide_tree.children[1]\n",
    "    end\n",
    "    for nd in post_order(guide_tree)\n",
    "        if (nd.nchild == 1)\n",
    "            delete_node!(nd)\n",
    "        end\n",
    "    end\n",
    "    for nd in get_leaves(guide_tree)\n",
    "        language = nd.name\n",
    "        nd_words = words[findall(taxa .== language)]\n",
    "        while length(nd_words) > 1\n",
    "            nd1 = Node()\n",
    "            nd2 = Node()\n",
    "            nd1.name = pop!(nd_words)\n",
    "            nd1.name = language * \":\" * nd1.name\n",
    "            add_child!(nd, nd1)\n",
    "            add_child!(nd, nd2)\n",
    "            nd = nd2\n",
    "        end\n",
    "        nd.name = nd_words[1]\n",
    "        nd.name = language * \":\" * nd.name\n",
    "    end\n",
    "\n",
    "    for (i, nd) in enumerate(post_order(guide_tree))\n",
    "        nd.num = i\n",
    "    end\n",
    "    guide_tree\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function get_alignment(data::DataFrame; tree::GeneralNode=tree, pmiPar::NW=pmiPar)\n",
    "    guide_tree = create_guide_tree(data; tree=tree)\n",
    "    al = tCoffee(guide_tree)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PMI Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NW{Char}(['!', '3', '4', '5', '7', '8', 'C', 'E', 'G', 'L'  …  'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'], Dict(('S', 'h') => -1.0026989942589113, ('s', 'S') => 2.318288217979542, ('j', 'N') => -1.7826427822252349, ('G', 'G') => 7.801431036430333, ('X', 'w') => -2.780066286502958, ('X', 'i') => -4.154471127478828, ('T', 'n') => -4.322710572125696, ('7', 'G') => 0.6133857200649624, ('G', 'y') => -0.454410510043628, ('T', 'v') => -1.70134002370793…), 2.41772332742949, 1.5084822877429087)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "par = CSV.read(\"../data/pmiParameters.csv\", DataFrame)\n",
    "\n",
    "pmi = CSV.read(\"../data/pmi.csv\", DataFrame)[:,2:end] |> Array\n",
    "\n",
    "sounds = first.(CSV.read(\"../data/pmi.csv\", DataFrame)[:,1])\n",
    "\n",
    "pmiDict = Dict{Tuple{Char, Char}, Float64}()\n",
    "\n",
    "for (i, s1) in enumerate(sounds), (j, s2) in enumerate(sounds)\n",
    "    pmiDict[s1, s2] = pmi[i,j]\n",
    "end\n",
    "\n",
    "pmiPar = NW(\n",
    "    sounds,\n",
    "    pmiDict,\n",
    "    par[1,1],\n",
    "    par[1,2],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_pmidists (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function compute_pmidists(languages, dMtx, pmiPar, maxSim, minSim)\n",
    "    index_pairs = [(i,j) for i in 1:length(languages), j in 1:length(languages) if i < j]\n",
    "    pmidists = zeros(Union{Float64, Missing}, (length(languages), length(languages)))\n",
    "    @showprogress @threads for (i,j) in index_pairs\n",
    "        pmidists[i, j] = pmidists[j, i] = dercPMI(i, j, pmiPar, dMtx, maxSim, minSim)\n",
    "    end\n",
    "    pmidists[ismissing.(pmidists)] .= mean(skipmissing(pmidists))\n",
    "    return pmidists\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_tree (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function build_tree(pmidists, languages)\n",
    "    R\"\"\"\n",
    "    library(phangorn)\n",
    "    dst = $pmidists\n",
    "    rownames(dst) <- colnames(dst) <- $languages\n",
    "    tree <- upgma(dst)\n",
    "    treeS <- write.tree(tree, file=\"\")\n",
    "    \"\"\"\n",
    "    return ParseNewick(@rget treeS)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_alignments (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_alignments(concepts, d, tree)\n",
    "    alignments = Dict()\n",
    "    for c in concepts\n",
    "        data = filter(x -> x.Concepticon_Gloss == c, d)\n",
    "        alignments[c] = get_alignment(data; tree=tree)\n",
    "    end\n",
    "    return alignments\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_character_matrix (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function create_character_matrix(concepts, alignments)\n",
    "    concept_char_mtc = []\n",
    "    for c in concepts\n",
    "        al = alignments[c]\n",
    "        @pipe al |>\n",
    "              1 .- ismissing.(Array(_[:, 2:end])) |>\n",
    "              DataFrame(_, :auto) |>\n",
    "              insertcols!(_, 1, :language => al.language) |>\n",
    "              groupby(_, :language) |>\n",
    "              combine(_, names(_, Not(:language)) .=> maximum) |>\n",
    "              push!(concept_char_mtc, _)\n",
    "    end\n",
    "    char_mtx = outerjoin(concept_char_mtc..., on=:language, makeunique=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "write_nexus_file (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function write_nexus_file(char_mtx, db_name)\n",
    "    nex = \"\"\"\n",
    "    #NEXUS\n",
    "\n",
    "    Begin data;\n",
    "    Dimensions ntax=$(size(char_mtx, 1)) nchar = $(size(char_mtx, 2) - 1);\n",
    "    Format datatype=restriction gap=-;\n",
    "    MATRIX\n",
    "    \"\"\"\n",
    "    pad = maximum(length.(char_mtx.language)) + 5\n",
    "    for i in 1:size(char_mtx, 1)\n",
    "        l = char_mtx.language[i]\n",
    "        ln = \"   \" * rpad(l, pad)\n",
    "        row = join(replace(char_mtx[i, 2:end] |> Vector, missing => \"-\"))\n",
    "        ln *= row * \"\\n\"\n",
    "        nex *= ln\n",
    "    end\n",
    "    nex *= \"\"\"\n",
    "    ;\n",
    "    End;\n",
    "    \"\"\"\n",
    "    open(joinpath(\"mrbayes\", \"$(db_name)_msa.nex\"), \"w\") do f\n",
    "        write(f, nex)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "write_phylip_file (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function write_phylip_file(char_mtx, db_name)\n",
    "    mkpath(\"phylip\")\n",
    "    phy = \"\"\"\n",
    "    $(size(char_mtx, 1)) $(size(char_mtx, 2) - 1)\n",
    "    \"\"\"\n",
    "    pad = maximum(length.(char_mtx.language)) + 5\n",
    "    for i in 1:size(char_mtx, 1)\n",
    "        l = char_mtx.language[i]\n",
    "        ln = \"   \" * rpad(l, pad)\n",
    "        row = join(replace(char_mtx[i, 2:end] |> Vector, missing => \"-\"))\n",
    "        ln *= row * \"\\n\"\n",
    "        phy *= ln\n",
    "    end\n",
    "    open(joinpath(\"phylip\", \"$(db_name)_msa.phy\"), \"w\") do f\n",
    "        write(f, phy)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "write_mrbayes_file (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function write_mrbayes_file(db_name)\n",
    "    mb = \"\"\"#Nexus\n",
    "    Begin MrBayes;\n",
    "        execute $(db_name)_msa.nex;\n",
    "        prset brlenspr = clock:uniform;\n",
    "        prset clockvarpr = igr;\n",
    "        lset rates=gamma;\n",
    "        lset covarion=yes;\n",
    "        prset clockratepr=exp(1.0);\n",
    "        lset coding=noabsencesites;\n",
    "        mcmcp stoprule=no stopval=0.01 filename=output/$(db_name)_msa samplefreq=1000;\n",
    "        mcmc ngen=10000000 nchains=2 nruns=2 append=no;\n",
    "        sumt;\n",
    "        sump;\n",
    "        q;\n",
    "    end;\n",
    "    \"\"\"\n",
    "    open(joinpath(\"mrbayes\", \"$(db_name)_msa.mb.nex\"), \"w\") do f\n",
    "        write(f, mb)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Processing abvdoceanic\n",
      "└ @ Main /localscratch/nwsja01/projects/msa_vs_cognates/code/create_msas.ipynb:2\n",
      "\u001b[32mProgress:   1%|▎                                        |  ETA: 7:37:27\u001b[39m\u001b[KK[39m\u001b[K"
     ]
    }
   ],
   "source": [
    "for db ∈ dbs\n",
    "    @info \"Processing $db\"\n",
    "    d = filter(x -> x.db == db, wl)\n",
    "    languages = unique(d.Glottocode)\n",
    "    if length(languages) < 4\n",
    "        @warn \"Skipping $db: Not enough languages\"\n",
    "        continue\n",
    "    end\n",
    "    concepts = unique(d.Concepticon_Gloss)\n",
    "    d_wide = unstack(d, :Glottocode, :Concepticon_Gloss, :ASJP, allowmissing=true, combine=x -> join(unique(x), \"-\"))\n",
    "    ln2index = Dict(zip(d_wide.Glottocode, 1:size(d_wide, 1)))\n",
    "    dMtx = Matrix(d_wide[:, 2:end])\n",
    "    nconcepts = length(concepts)\n",
    "    minSim = -sqrt(nconcepts)\n",
    "    maxSim = (log(nconcepts * (nconcepts - 1) + 1) - 1) * sqrt(nconcepts)\n",
    "    pmidists = compute_pmidists(languages, dMtx, pmiPar, maxSim, minSim)\n",
    "    tree = build_tree(pmidists, languages)\n",
    "    alignments = get_alignments(concepts, d, tree)\n",
    "    char_mtx = create_character_matrix(concepts, alignments)\n",
    "    db_name = split(split(db, \"/\")[end], \".\")[1]\n",
    "    write_nexus_file(char_mtx, db_name)\n",
    "    write_phylip_file(char_mtx, db_name)\n",
    "    write_mrbayes_file(db_name)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
